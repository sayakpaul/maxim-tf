{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00a3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29530cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 12:19:05.108512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from create_maxim_model import Model\n",
    "from maxim.configs import MAXIM_CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f817755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 12:19:08.347836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# From https://github.com/google-research/maxim/blob/main/maxim/run_eval.py#L55\n",
    "\n",
    "VARIANT = \"S-3\"\n",
    "configs = MAXIM_CONFIGS.get(VARIANT)\n",
    "\n",
    "configs.update(\n",
    "    {\n",
    "        \"variant\": VARIANT,\n",
    "        \"dropout_rate\": 0.0,\n",
    "        \"num_outputs\": 3,\n",
    "        \"use_bias\": True,\n",
    "        \"num_supervision_scales\": 3,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = Model(**configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767355f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/google-research/maxim/blob/main/maxim/run_eval.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections \n",
    "import io\n",
    "\n",
    "\n",
    "def recover_tree(keys, values):\n",
    "    \"\"\"Recovers a tree as a nested dict from flat names and values.\n",
    "    This function is useful to analyze checkpoints that are saved by our programs\n",
    "    without need to access the exact source code of the experiment. In particular,\n",
    "    it can be used to extract an reuse various subtrees of the scheckpoint, e.g.\n",
    "    subtree of parameters.\n",
    "    Args:\n",
    "      keys: a list of keys, where '/' is used as separator between nodes.\n",
    "      values: a list of leaf values.\n",
    "    Returns:\n",
    "      A nested tree-like dict.\n",
    "    \"\"\"\n",
    "    tree = {}\n",
    "    sub_trees = collections.defaultdict(list)\n",
    "    for k, v in zip(keys, values):\n",
    "        if \"/\" not in k:\n",
    "            tree[k] = v\n",
    "        else:\n",
    "            k_left, k_right = k.split(\"/\", 1)\n",
    "            sub_trees[k_left].append((k_right, v))\n",
    "    for k, kv_pairs in sub_trees.items():\n",
    "        k_subtree, v_subtree = zip(*kv_pairs)\n",
    "        tree[k] = recover_tree(k_subtree, v_subtree)\n",
    "    return tree\n",
    "\n",
    "\n",
    "def get_params(ckpt_path):\n",
    "    \"\"\"Get params checkpoint.\"\"\"\n",
    "\n",
    "    with tf.io.gfile.GFile(ckpt_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    values = np.load(io.BytesIO(data))\n",
    "    params = recover_tree(*zip(*values.items()))\n",
    "    params = params[\"opt\"][\"target\"]\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b443a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = \"gs://gresearch/maxim/ckpt/Denoising/SIDD/checkpoint.npz\"\n",
    "jax_params = get_params(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ec54e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.212795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d959073f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UpSampleRatio_0',\n",
       " 'UpSampleRatio_1',\n",
       " 'UpSampleRatio_10',\n",
       " 'UpSampleRatio_11',\n",
       " 'UpSampleRatio_12']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(jax_params.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81fbc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_vars(model):\n",
    "    model_variables = model.variables\n",
    "    model_variables_dict = {}\n",
    "    for v in model_variables:\n",
    "        model_variables_dict[v.name] = v\n",
    "\n",
    "    return model_variables_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8060efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_params = get_model_vars(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "162f7382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stage_0_input_conv_0/kernel:0',\n",
       " 'stage_0_input_conv_0/bias:0',\n",
       " 'stage_0_encoder_block_0_conv_in/kernel:0',\n",
       " 'stage_0_encoder_block_0_conv_in/bias:0',\n",
       " 'stage_0_encoder_block_0_SplitHeadMultiAxisGmlpLayer_0_LayerNorm_in/gamma:0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tf_params.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832a74bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['UpSampleRatio_0', 'UpSampleRatio_1', 'UpSampleRatio_10', 'UpSampleRatio_11', 'UpSampleRatio_12', 'UpSampleRatio_13', 'UpSampleRatio_14', 'UpSampleRatio_15', 'UpSampleRatio_16', 'UpSampleRatio_17', 'UpSampleRatio_18', 'UpSampleRatio_19', 'UpSampleRatio_2', 'UpSampleRatio_20', 'UpSampleRatio_21', 'UpSampleRatio_22', 'UpSampleRatio_23', 'UpSampleRatio_24', 'UpSampleRatio_25', 'UpSampleRatio_26', 'UpSampleRatio_27', 'UpSampleRatio_28', 'UpSampleRatio_29', 'UpSampleRatio_3', 'UpSampleRatio_30', 'UpSampleRatio_31', 'UpSampleRatio_32', 'UpSampleRatio_33', 'UpSampleRatio_34', 'UpSampleRatio_35', 'UpSampleRatio_36', 'UpSampleRatio_37', 'UpSampleRatio_38', 'UpSampleRatio_39', 'UpSampleRatio_4', 'UpSampleRatio_40', 'UpSampleRatio_41', 'UpSampleRatio_42', 'UpSampleRatio_43', 'UpSampleRatio_44', 'UpSampleRatio_45', 'UpSampleRatio_46', 'UpSampleRatio_47', 'UpSampleRatio_48', 'UpSampleRatio_49', 'UpSampleRatio_5', 'UpSampleRatio_50', 'UpSampleRatio_51', 'UpSampleRatio_52', 'UpSampleRatio_53', 'UpSampleRatio_6', 'UpSampleRatio_7', 'UpSampleRatio_8', 'UpSampleRatio_9', 'stage_0_cross_gating_block_0', 'stage_0_cross_gating_block_1', 'stage_0_cross_gating_block_2', 'stage_0_decoder_block_0', 'stage_0_decoder_block_1', 'stage_0_decoder_block_2', 'stage_0_encoder_block_0', 'stage_0_encoder_block_1', 'stage_0_encoder_block_2', 'stage_0_global_block_0', 'stage_0_global_block_1', 'stage_0_input_conv_0', 'stage_0_input_conv_1', 'stage_0_input_conv_2', 'stage_0_supervised_attention_module_0', 'stage_0_supervised_attention_module_1', 'stage_0_supervised_attention_module_2', 'stage_1_cross_gating_block_0', 'stage_1_cross_gating_block_1', 'stage_1_cross_gating_block_2', 'stage_1_decoder_block_0', 'stage_1_decoder_block_1', 'stage_1_decoder_block_2', 'stage_1_encoder_block_0', 'stage_1_encoder_block_1', 'stage_1_encoder_block_2', 'stage_1_global_block_0', 'stage_1_global_block_1', 'stage_1_input_conv_0', 'stage_1_input_conv_1', 'stage_1_input_conv_2', 'stage_1_input_fuse_sam_0', 'stage_1_input_fuse_sam_1', 'stage_1_input_fuse_sam_2', 'stage_1_supervised_attention_module_0', 'stage_1_supervised_attention_module_1', 'stage_1_supervised_attention_module_2', 'stage_2_cross_gating_block_0', 'stage_2_cross_gating_block_1', 'stage_2_cross_gating_block_2', 'stage_2_decoder_block_0', 'stage_2_decoder_block_1', 'stage_2_decoder_block_2', 'stage_2_encoder_block_0', 'stage_2_encoder_block_1', 'stage_2_encoder_block_2', 'stage_2_global_block_0', 'stage_2_global_block_1', 'stage_2_input_conv_0', 'stage_2_input_conv_1', 'stage_2_input_conv_2', 'stage_2_input_fuse_sam_0', 'stage_2_input_fuse_sam_1', 'stage_2_input_fuse_sam_2', 'stage_2_output_conv_0', 'stage_2_output_conv_1', 'stage_2_output_conv_2'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax_params.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
