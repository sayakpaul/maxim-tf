{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00a3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29530cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 11:30:43.536748: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from create_maxim_model import Model\n",
    "from maxim.configs import MAXIM_CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f817755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/google-research/maxim/blob/main/maxim/run_eval.py#L55\n",
    "\n",
    "VARIANT = \"S-3\"\n",
    "configs = MAXIM_CONFIGS.get(VARIANT)\n",
    "\n",
    "configs.update(\n",
    "    {\n",
    "        \"variant\": VARIANT,\n",
    "        \"dropout_rate\": 0.0,\n",
    "        \"num_outputs\": 3,\n",
    "        \"use_bias\": True,\n",
    "        \"num_supervision_scales\": 3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767355f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/google-research/maxim/blob/main/maxim/run_eval.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections \n",
    "import re\n",
    "import io\n",
    "\n",
    "\n",
    "def recover_tree(keys, values):\n",
    "    \"\"\"Recovers a tree as a nested dict from flat names and values.\n",
    "    This function is useful to analyze checkpoints that are saved by our programs\n",
    "    without need to access the exact source code of the experiment. In particular,\n",
    "    it can be used to extract an reuse various subtrees of the scheckpoint, e.g.\n",
    "    subtree of parameters.\n",
    "    Args:\n",
    "      keys: a list of keys, where '/' is used as separator between nodes.\n",
    "      values: a list of leaf values.\n",
    "    Returns:\n",
    "      A nested tree-like dict.\n",
    "    \"\"\"\n",
    "    tree = {}\n",
    "    sub_trees = collections.defaultdict(list)\n",
    "    for k, v in zip(keys, values):\n",
    "        if \"/\" not in k:\n",
    "            tree[k] = v\n",
    "        else:\n",
    "            k_left, k_right = k.split(\"/\", 1)\n",
    "            sub_trees[k_left].append((k_right, v))\n",
    "    for k, kv_pairs in sub_trees.items():\n",
    "        k_subtree, v_subtree = zip(*kv_pairs)\n",
    "        tree[k] = recover_tree(k_subtree, v_subtree)\n",
    "    return tree\n",
    "\n",
    "\n",
    "def get_params(ckpt_path):\n",
    "    \"\"\"Get params checkpoint.\"\"\"\n",
    "\n",
    "    with tf.io.gfile.GFile(ckpt_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    values = np.load(io.BytesIO(data))\n",
    "    params = recover_tree(*zip(*values.items()))\n",
    "    params = params[\"opt\"][\"target\"]\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401bcfdb",
   "metadata": {},
   "source": [
    "```\n",
    "gamma => scale\n",
    "beta => bias\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f548473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5491913/sorting-list-in-python\n",
    "def sort_nicely(l): \n",
    "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\" \n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd7c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_upsample(jax_params):\n",
    "    modified_jax_params = collections.OrderedDict()\n",
    "\n",
    "    jax_keys = list(jax_params.keys())\n",
    "    keys_upsampling = []\n",
    "    for k in range(len(jax_keys)):\n",
    "        if \"UpSample\" in jax_keys[k]:\n",
    "            keys_upsampling.append(jax_keys[k])\n",
    "    sorted_keys_upsampling = sort_nicely(keys_upsampling)\n",
    "    \n",
    "    i = 1\n",
    "    for k in sorted_keys_upsampling:\n",
    "        k_t = k.split(\"_\")[0] + \"_\" + str(i)\n",
    "        i += 1\n",
    "        for j in jax_params[k]:\n",
    "            for l in jax_params[k][j]:\n",
    "                modified_param_name = f\"{k_t}_{j}/{l}:0\"\n",
    "                params = jax_params[k][j][l]\n",
    "                modified_jax_params.update({modified_param_name: params})\n",
    "\n",
    "    return modified_jax_params\n",
    "\n",
    "\n",
    "def modify_jax_params(jax_params):\n",
    "    modified_jax_params = collections.OrderedDict()\n",
    "\n",
    "    for k in jax_params:\n",
    "        if \"UpSample\" not in k:\n",
    "            params = jax_params[k]\n",
    "\n",
    "            if (\"ConvTranspose\" in k) and (\"bias\" not in k):\n",
    "                params = params.transpose(0, 1, 3, 2)\n",
    "\n",
    "            split_names = k.split(\"_\")\n",
    "            modified_param_name = (\n",
    "                \"_\".join(split_names[0:-1]) + \"/\" + split_names[-1] + \":0\"\n",
    "            )\n",
    "\n",
    "            if \"layernorm\" in modified_param_name.lower():\n",
    "                if \"scale\" in modified_param_name:\n",
    "                    modified_param_name = modified_param_name.replace(\"scale\", \"gamma\")\n",
    "                elif \"bias\" in modified_param_name:\n",
    "                    modified_param_name = modified_param_name.replace(\"bias\", \"beta\")\n",
    "\n",
    "            modified_jax_params.update({modified_param_name: params})\n",
    "\n",
    "    return modified_jax_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59a2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_jax_params(configs, ckpt_path):\n",
    "    # Initialize TF Model.\n",
    "    tf_model = Model(**configs)\n",
    "    \n",
    "    # Obtain a mapping of the TF variable names and their values.\n",
    "    tf_model_variables = tf_model.variables\n",
    "    tf_model_variables_dict = {}\n",
    "    for v in tf_model_variables:\n",
    "        tf_model_variables_dict[v.name] = v\n",
    "        \n",
    "    # Obtain the JAX pre-trained variables.\n",
    "    jax_params = get_params(ckpt_path)\n",
    "    [flat_jax_dict] = pd.json_normalize(jax_params, sep=\"_\").to_dict(orient=\"records\")\n",
    "    \n",
    "    # Amend the JAX variables to match the names of the TF variables.\n",
    "    modified_jax_params = modify_jax_params(flat_jax_dict)\n",
    "    modified_jax_params.update(modify_upsample(jax_params))\n",
    "    \n",
    "    # Porting.\n",
    "    tf_weights = []\n",
    "    i = 0\n",
    "\n",
    "    for k in modified_jax_params:\n",
    "        param = modified_jax_params[k]\n",
    "        tf_weights.append((tf_model_variables_dict[k], param))\n",
    "        i += 1\n",
    "\n",
    "    assert i == len(modified_jax_params) == len(tf_model_variables_dict)\n",
    "\n",
    "    tf.keras.backend.batch_set_value(tf_weights)\n",
    "\n",
    "    return modified_jax_params, tf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27a99a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 11:30:46.924935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "_, tf_model = port_jax_params(\n",
    "    configs, \"gs://gresearch/maxim/ckpt/Denoising/SIDD/checkpoint.npz\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
