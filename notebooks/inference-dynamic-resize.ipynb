{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/maxim-tf/blob/main/notebooks/inference-dynamic-resize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxgb-sWfpb49"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook shows how to run inference with the [MAXIM family of models](https://github.com/google-research/maxim) from [TensorFlow Hub](https://tfhub.dev/sayakpaul/collections/maxim/1). MAXIM family of models share the same backbone for performing: denoising, dehazing, deblurring, deraining, and enhancement. You can know more about the public MAXIM models from [here](https://github.com/google-research/maxim#results-and-pre-trained-models).\n",
        "\n",
        "This notebook allows you to run dynamic shaped images unlike [this one](https://github.com/sayakpaul/maxim-tf/blob/main/notebooks/inference.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlp7twW3tB2n"
      },
      "source": [
        "## Select a checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-n8jA4Gojv2"
      },
      "outputs": [],
      "source": [
        "task = \"Deblurring\"  # @param [\"Denoising\", \"Dehazing_Indoor\", \"Dehazing_Outdoor\", \"Deblurring\", \"Deraining\", \"Enhancement\", \"Retouching\"]\n",
        "\n",
        "model_handle_map = {\n",
        "    \"Denoising\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-3_denoising_sidd/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Denoising/input/0003_30.png\",\n",
        "    ],\n",
        "    \"Dehazing_Indoor\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_dehazing_sots-indoor/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Dehazing/input/0003_0.8_0.2.png\",\n",
        "    ],\n",
        "    \"Dehazing_Outdoor\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_dehazing_sots-outdoor/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Dehazing/input/1444_10.png\",\n",
        "    ],\n",
        "    \"Deblurring\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_gopro/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Deblurring/input/1fromGOPR0950.png\",\n",
        "    ],\n",
        "    \"Deraining\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_deraining_raindrop/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Deraining/input/15.png\",\n",
        "    ],\n",
        "    \"Enhancement\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_enhancement_lol/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Enhancement/input/a4541-DSC_0040-2.png\",\n",
        "    ],\n",
        "    \"Retouching\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_enhancement_fivek/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Enhancement/input/a4541-DSC_0040-2.png\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "model_handle = model_handle_map[task]\n",
        "ckpt = model_handle[0]\n",
        "print(f\"TF-Hub handle: {ckpt}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t6c3Z1Pz6UT"
      },
      "source": [
        "For deblurring, there are other checkpoints too:\n",
        "\n",
        "- https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_realblur_r/1\n",
        "- https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_realblur_j/1\n",
        "- https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_reds/1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNlQ2HzrtJOU"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEhpgokqtKFz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/sayakpaul/maxim-tf.git\n",
        "%cd maxim-tf\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us19UdxvdE18"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from create_maxim_model import Model\n",
        "from maxim.configs import MAXIM_CONFIGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEtzvxy5dE18"
      },
      "source": [
        "TODO: When the repository is public, clone it and use accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTdrCvUltkCn"
      },
      "source": [
        "## Fetch the input image based on the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn90H1rltRcM"
      },
      "outputs": [],
      "source": [
        "image_url = model_handle[1]\n",
        "image_path = tf.keras.utils.get_file(origin=image_url)\n",
        "Image.open(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs1FCtINdE19"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "z = hub.resolve(model_handle[0])\n",
        "_MODEL = tf.keras.models.load_model(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsXRY1kvum4O"
      },
      "source": [
        "## Preprocessing utilities\n",
        "\n",
        "Based on [this official script](https://github.com/google-research/maxim/blob/main/maxim/run_eval.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGmgEtfLt7S5"
      },
      "outputs": [],
      "source": [
        "def mod_padding_symmetric(image, factor=64):\n",
        "    \"\"\"Padding the image to be divided by factor.\"\"\"\n",
        "    height, width = image.shape[0], image.shape[1]\n",
        "    height_pad, width_pad = ((height + factor) // factor) * factor, (\n",
        "        (width + factor) // factor\n",
        "    ) * factor\n",
        "    padh = height_pad - height if height % factor != 0 else 0\n",
        "    padw = width_pad - width if width % factor != 0 else 0\n",
        "    image = tf.pad(\n",
        "        image, [(padh // 2, padh // 2), (padw // 2, padw // 2), (0, 0)], mode=\"REFLECT\"\n",
        "    )\n",
        "    return image\n",
        "\n",
        "\n",
        "def make_shape_even(image):\n",
        "    \"\"\"Pad the image to have even shapes.\"\"\"\n",
        "    height, width = image.shape[0], image.shape[1]\n",
        "    padh = 1 if height % 2 != 0 else 0\n",
        "    padw = 1 if width % 2 != 0 else 0\n",
        "    image = tf.pad(image, [(0, padh), (0, padw), (0, 0)], mode=\"REFLECT\")\n",
        "    return image\n",
        "\n",
        "\n",
        "def process_image(image: Image):\n",
        "    input_img = np.asarray(image) / 255.0\n",
        "    height, width = input_img.shape[0], input_img.shape[1]\n",
        "\n",
        "    # Padding images to have even shapes\n",
        "    input_img = make_shape_even(input_img)\n",
        "    height_even, width_even = input_img.shape[0], input_img.shape[1]\n",
        "\n",
        "    # padding images to be multiplies of 64\n",
        "    input_img = mod_padding_symmetric(input_img, factor=64)\n",
        "    input_img = tf.expand_dims(input_img, axis=0)\n",
        "    return input_img, height, width, height_even, width_even\n",
        "\n",
        "\n",
        "def init_new_model(input_img):\n",
        "    variant = ckpt.split(\"/\")[-1].split(\"_\")[0]\n",
        "    configs = MAXIM_CONFIGS.get(variant)\n",
        "    configs.update(\n",
        "        {\n",
        "            \"variant\": \"S-2\",\n",
        "            \"dropout_rate\": 0.0,\n",
        "            \"num_outputs\": 3,\n",
        "            \"use_bias\": True,\n",
        "            \"num_supervision_scales\": 3,\n",
        "        }\n",
        "    )  # From https://github.com/google-research/maxim/blob/main/maxim/run_eval.py#L45-#L61\n",
        "    configs.update({\"input_resolution\": (input_img.shape[1], input_img.shape[2])})\n",
        "    new_model = Model(**configs)\n",
        "    new_model.set_weights(_MODEL.get_weights())\n",
        "    return new_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVOdyjTudE1_"
      },
      "source": [
        "To make the model operate on images of arbitrary shapes here's what we're doing:\n",
        "\n",
        "* Loading the initial pre-trained model into `_MODEL`.\n",
        "* Initializing a separate instance of MAXIM based on the configs and spatial resolutions of the input image.\n",
        "* Populating the params of this newly initialized model with that of `_MODEL`. \n",
        "\n",
        "All of it is handled in `init_new_model()`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T20A1xLvcLq"
      },
      "source": [
        "## Run predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOxESHl2vdRE"
      },
      "outputs": [],
      "source": [
        "# Based on https://github.com/google-research/maxim/blob/main/maxim/run_eval.py\n",
        "def infer(image_path: str):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    preprocessed_image, height, width, height_even, width_even = process_image(image)\n",
        "    new_model = init_new_model(preprocessed_image)\n",
        "\n",
        "    preds = new_model.predict(preprocessed_image)\n",
        "    if isinstance(preds, list):\n",
        "        preds = preds[-1]\n",
        "        if isinstance(preds, list):\n",
        "            preds = preds[-1]\n",
        "\n",
        "    preds = np.array(preds[0], np.float32)\n",
        "\n",
        "    new_height, new_width = preds.shape[0], preds.shape[1]\n",
        "    h_start = new_height // 2 - height_even // 2\n",
        "    h_end = h_start + height\n",
        "    w_start = new_width // 2 - width_even // 2\n",
        "    w_end = w_start + width\n",
        "    preds = preds[h_start:h_end, w_start:w_end, :]\n",
        "\n",
        "    return np.array(np.clip(preds, 0.0, 1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fr-rYLpwab6"
      },
      "outputs": [],
      "source": [
        "final_pred_image = infer(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTq1J42tw67G"
      },
      "source": [
        "## Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECGdFWQBw8E2"
      },
      "outputs": [],
      "source": [
        "# Based on https://www.tensorflow.org/lite/examples/style_transfer/overview#visualize_the_inputs\n",
        "def imshow(image, title=None):\n",
        "    if len(image.shape) > 3:\n",
        "        image = tf.squeeze(image, axis=0)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "input_image = np.asarray(Image.open(image_path).convert(\"RGB\"), np.float32) / 255.0\n",
        "imshow(input_image, \"Input Image\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(final_pred_image, \"Predicted Image\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
